{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a GP and sample from it directly on some pre-defined positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary packages\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy.linalg \n",
    "from scipy.special import cbrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PermeabilityModel(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A stochastic model for permeability.\n",
    "\n",
    "    :param X1:  x coordinates of grid\n",
    "    :param X2:  y coordinates of grid\n",
    "    :param X3:  z coordinates of grid\n",
    "    :param cov: a covariance function\n",
    "    :param K0:  a geometric mean level for the field\n",
    "    :param X:   observed inputs\n",
    "    :param Y:   observed outputs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X1, X2, X3, cov, mu0=0., X=None, Y=None, nugget=1e-12):\n",
    "        self.cov = cov\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.X3 = X3\n",
    "        n = np.prod(X1.shape)\n",
    "        self.n = n\n",
    "        self.mu0 = mu0\n",
    "        self.X_all = np.hstack([X1.flatten()[:, None], X2.flatten()[:, None], X3.flatten()[:, None]])\n",
    "        if X is not None:\n",
    "            CX = cov.K(X) + nugget * np.eye(X.shape[0])\n",
    "            L = np.linalg.cholesky(CX)\n",
    "            self.LiY = np.linalg.solve(L, Y - mu0)\n",
    "            CXaX = cov.K(self.X_all, X)\n",
    "            self.G0 = self.mu0 + np.dot(CXaX, self.LiY).reshape(self.X1.shape)\n",
    "            self.C = cov.K(self.X_all) - np.dot(CXaX, CXaX.T) + nugget * np.eye(self.X_all.shape[0])\n",
    "        else:\n",
    "            self.C = cov.K(self.X_all) + nugget * np.eye(self.X_all.shape[0])\n",
    "            self.G0 = np.ones(self.X1.shape) * mu0\n",
    "        self.L = np.linalg.cholesky(self.C)\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Sample the model.\n",
    "        \"\"\"\n",
    "        g = np.dot(self.L, np.random.randn(self.L.shape[0]))\n",
    "        G = g.reshape(self.X1.shape)\n",
    "        return self.G0 + G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem parameters\n",
    "x1_L = 250. \n",
    "x2_L = 50.\n",
    "x3_L = 1. # depth\n",
    "Nx = 15\n",
    "Ny = 15\n",
    "Nz = 15   # layers in depth\n",
    "\n",
    "x1 = np.linspace(0, 1, Nx)\n",
    "x2 = np.linspace(0, 1, Ny)\n",
    "x3 = np.linspace(0, 1, Nz)\n",
    "X1, X2, X3 = np.meshgrid(x1, x2, x3)\n",
    "k = GPy.kern.Exponential(3, ARD=True, lengthscale=[50./250, 5./50, 1], variance=0.25)\n",
    "perm_X = PermeabilityModel(X1, X2, X3, k, mu0=-23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15, 15)\n",
      "-22.986017001884434\n",
      "-9.982700344852736\n",
      "0.20822739201674728\n"
     ]
    }
   ],
   "source": [
    "G = perm_X.sample() # Sampled log permeability\n",
    "print G.shape\n",
    "print np.mean(G.flatten())\n",
    "print np.mean(np.log10(np.exp(G.flatten())))\n",
    "print np.var(G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling is fast\n",
    "Kxs = []\n",
    "for i in xrange(5):\n",
    "    Kx = np.exp(perm_X.sample())\n",
    "#     print i\n",
    "    Kxs.append(Kx)\n",
    "# Kxs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize at a specific x y location as a function of depth\n",
    "# plt.plot(Kxs[0][1, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94420ff0fb89411abe06af4a99e0a8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0wLCBkZXNjcmlwdGlvbj11J2RlcHRoJywgbWF4PTE0KSwgT3V0cHV0KCkpLCBfZG9tX2NsYXNzZXM9KHUnd2lkZ2V0LWludGXigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize one sample for various depths\n",
    "def plot_contour(depth=0):\n",
    "    fig, ax = plt.subplots()\n",
    "#     c = ax.contourf(X1[:, :, 0], X2[:, :, 0], Kxs[0][:, :, depth])\n",
    "    c = ax.contourf(X1[:, :, 0], X2[:, :, 0], np.log10(Kxs[4][:, :, depth]))\n",
    "\n",
    "    plt.colorbar(c)\n",
    "    ax.set_aspect(0.2)    \n",
    "from ipywidgets import interactive\n",
    "interactive(plot_contour, depth=(0, 14, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05        0.05        0.03333333]\n",
      " [ 0.05        0.05        0.1       ]\n",
      " [ 0.05        0.05        0.16666667]\n",
      " [ 0.05        0.05        0.23333333]\n",
      " [ 0.05        0.05        0.3       ]\n",
      " [ 0.05        0.05        0.36666667]\n",
      " [ 0.05        0.05        0.43333333]\n",
      " [ 0.05        0.05        0.5       ]\n",
      " [ 0.05        0.05        0.56666667]\n",
      " [ 0.05        0.05        0.63333333]\n",
      " [ 0.05        0.05        0.7       ]\n",
      " [ 0.05        0.05        0.76666667]\n",
      " [ 0.05        0.05        0.83333333]\n",
      " [ 0.05        0.05        0.9       ]\n",
      " [ 0.05        0.05        0.96666667]\n",
      " [ 0.95        0.95        0.03333333]\n",
      " [ 0.95        0.95        0.1       ]\n",
      " [ 0.95        0.95        0.16666667]\n",
      " [ 0.95        0.95        0.23333333]\n",
      " [ 0.95        0.95        0.3       ]\n",
      " [ 0.95        0.95        0.36666667]\n",
      " [ 0.95        0.95        0.43333333]\n",
      " [ 0.95        0.95        0.5       ]\n",
      " [ 0.95        0.95        0.56666667]\n",
      " [ 0.95        0.95        0.63333333]\n",
      " [ 0.95        0.95        0.7       ]\n",
      " [ 0.95        0.95        0.76666667]\n",
      " [ 0.95        0.95        0.83333333]\n",
      " [ 0.95        0.95        0.9       ]\n",
      " [ 0.95        0.95        0.96666667]]\n",
      "[[-12.23047034 -12.46040948 -12.33039661   0.213     ]\n",
      " [-12.13297777 -12.21684148 -12.17288847   0.204     ]\n",
      " [-11.90534605 -11.97552181 -11.93901805   0.215     ]\n",
      " [-12.40583353 -12.41800563 -12.41187694   0.23      ]\n",
      " [-12.18029048 -12.21053201 -12.19514807   0.232     ]\n",
      " [-12.37528872 -12.42251782 -12.39826157   0.207     ]\n",
      " [-12.48720266 -12.53150033 -12.50878695   0.225     ]\n",
      " [-12.40365661 -12.42479162 -12.41409556   0.21      ]\n",
      " [-12.76267855 -12.82962534 -12.79486323   0.2       ]\n",
      " [-12.09349454 -12.19548408 -12.14150227   0.211     ]\n",
      " [-12.113622   -12.1471794  -12.13007666   0.205     ]\n",
      " [-12.74089877 -12.75044409 -12.74564521   0.189     ]\n",
      " [-12.425933   -12.46289117 -12.44401907   0.194     ]\n",
      " [-12.97633282 -13.03723365 -13.0057166    0.148     ]\n",
      " [-13.52859534 -13.64398876 -13.58247072   0.121     ]\n",
      " [-12.75774333 -12.79352899 -12.77526768   0.175     ]\n",
      " [-13.31552052 -13.52859534 -13.4091195    0.121     ]\n",
      " [-11.85526719 -12.05051006 -11.94200804   0.216     ]\n",
      " [-12.54182361 -12.63650074 -12.58658729   0.207     ]\n",
      " [-11.89884605 -11.98868326 -11.94144584   0.214     ]\n",
      " [-11.92980484 -12.01582203 -11.97068732   0.217     ]\n",
      " [-12.49786073 -12.57435283 -12.53442489   0.209     ]\n",
      " [-12.78300013 -12.85342825 -12.81678811   0.195     ]\n",
      " [-12.73387499 -12.74089877 -12.73737268   0.206     ]\n",
      " [-12.90191288 -12.91581149 -12.90880658   0.194     ]\n",
      " [-11.86176548 -12.04524582 -11.94388729   0.21      ]\n",
      " [-12.15262707 -12.34675176 -12.23893208   0.212     ]\n",
      " [-12.07071345 -12.13297777 -12.10073072   0.211     ]\n",
      " [-12.04524582 -12.09190275 -12.06794803   0.2       ]\n",
      " [-12.01582203 -12.06470235 -12.03957487   0.201     ]]\n"
     ]
    }
   ],
   "source": [
    "well_num = 2\n",
    "dim = 3\n",
    "# we load well data here\n",
    "well1_data = np.loadtxt('data/well1.txt') #depth Kx Ky Kz porosity \n",
    "well2_data = np.loadtxt('data/well2.txt') #depth Kx Ky Kz porosity \n",
    "#converting well data \n",
    "well1_data[:,1:-1] = np.log10(1e-3*9.869233e-13*well1_data[:,1:-1])\n",
    "well1_data[:,4] = (1e-2*well1_data[:,4])\n",
    "well2_data[:,1:-1] = np.log10(1e-3*9.869233e-13*well2_data[:,1:-1])\n",
    "well2_data[:,4] = (1e-2*well2_data[:,4])\n",
    "# we model the fixed depth reservoir, thus we eliminate the extra information for well2 (min function)\n",
    "num_obs = well_num*min(len(well1_data),len(well2_data)) #if more wells add here\n",
    "X_obs = np.zeros ((num_obs, dim)) # (num_obs, dim) r = x1,x2,x3   \n",
    "Y_obs = np.zeros ((num_obs, 4))  # (num_obs, unknown parameters:Kx,Ky,Kz,porosity)                 \n",
    "# calculating cell-centers\n",
    "xc = np.zeros((Nx,Ny,Nz))\n",
    "yc = np.zeros((Nx,Ny,Nz))\n",
    "zc = np.zeros((Nx,Ny,Nz))\n",
    "for i in range(0,Nx):\n",
    "  for j in range(0,Ny):\n",
    "    for k in range(0,Nz):\n",
    "        xc[i,j,k] = (i+0.5)*x1_L/Nx/x1_L #we divide by x1_L to normalize xc\n",
    "        yc[i,j,k] = (j+0.5)*x2_L/Ny/x2_L\n",
    "        zc[i,j,k] = (k+0.5)*x3_L/Nz/x3_L\n",
    "# we construct the observation coordinates and values here in X_obs and Y_obs, respectively \n",
    "# well1[i,j,k] --> 0,0,0-14, well2[i,j,k] --> 9,9,0-14\n",
    "for k in range(0,int(0.5*num_obs)): # we sweep along well1 in z\n",
    "    X_obs[k,:] = [xc[0,0,k],yc[0,0,k],zc[0,0,k]]\n",
    "    Y_obs[k,:] = well1_data[k,1:5]\n",
    "for k in range(int(0.5*num_obs),num_obs): # we sweep along well2 in z\n",
    "    X_obs[k,:] = [xc[9,9,k-int(0.5*num_obs)],yc[9,9,k-int(0.5*num_obs)],zc[9,9,k-int(0.5*num_obs)]]\n",
    "    Y_obs[k,:] = well2_data[k-int(0.5*num_obs),1:5]\n",
    "print X_obs\n",
    "print Y_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KarhunenLoeveExpansion(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    A class representing the Karhunen Loeve Expansion of a Gaussian random field.\n",
    "    It uses the Nystrom approximation to do it.\n",
    "    \n",
    "    Arguments:\n",
    "        k      -     The covariance function.\n",
    "        Xq     -     Quadrature points for the Nystrom approximation.\n",
    "        wq     -     Quadrature weights for the Nystrom approximation.\n",
    "        alpha  -     The percentage of the energy of the field that you want to keep.\n",
    "        X      -     Observed inputs (optional).\n",
    "        Y      -     Observed field values (optional).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k, Xq=None, wq=None, nq=100, alpha=0.9, X=None, Y=None):\n",
    "        self.k = k\n",
    "        if Xq is None:\n",
    "            if k.input_dim == 1:\n",
    "                Xq = np.linspace(0, 1, nq)[:, None]\n",
    "                wq = np.ones((nq, )) / nq\n",
    "            elif k.input_dim == 2:\n",
    "                #nq = int(np.sqrt(nq))\n",
    "                x = np.linspace(0, 1, nq)\n",
    "                X1, X2 = np.meshgrid(x, x)\n",
    "                Xq = np.hstack([X1.flatten()[:, None], X2.flatten()[:, None]])\n",
    "                wq = np.ones((nq ** 2, )) / nq ** 2\n",
    "            elif k.input_dim == 3:\n",
    "                #nq = int(cbrt(nq))\n",
    "                x = np.linspace(0, 1, nq)\n",
    "                X1, X2, X3 = np.meshgrid(x, x, x)\n",
    "                Xq = np.hstack([X1.flatten()[:, None], X2.flatten()[:, None], X3.flatten()[:, None]])\n",
    "                wq = np.ones((nq ** 3, )) / nq ** 3                \n",
    "            else:\n",
    "                raise NotImplementedError('For more than 3D, please supply quadrature points and weights.')\n",
    "        self.Xq = Xq\n",
    "        self.wq = wq\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        # If we have some observed data, we need to use the posterior covariance\n",
    "        if X is not None:\n",
    "            self.K = self.k.K(X) + 1e-12 * np.eye(X.shape[0])\n",
    "            self.L = np.linalg.cholesky(self.K)\n",
    "            self.LiY = np.linalg.solve(self.L, Y)\n",
    "            Kqp = self.k.K(Xq)\n",
    "            Kcp = self.k.K(X, Xq)\n",
    "            self.LiKcp = np.linalg.solve(self.L, Kcp)\n",
    "            Kq = Kqp - np.dot(self.LiKcp.T, self.LiKcp)\n",
    "            #gpr = GPy.models.GPRegression(X, Y[:, None], k)\n",
    "            #gpr.likelihood.variance = 1e-12\n",
    "            #self.gpr = gpr\n",
    "            #Kq = gpr.predict(Xq, full_cov=True)[1]\n",
    "        else:\n",
    "            Kq = k.K(Xq)\n",
    "        B = np.einsum('ij,j->ij', Kq, wq)\n",
    "        lam, v = scipy.linalg.eigh(B, overwrite_a=True)\n",
    "        lam = lam[::-1]\n",
    "        lam[lam <= 0.] = 0.\n",
    "        energy = np.cumsum(lam) / np.sum(lam)\n",
    "        i_end = np.arange(energy.shape[0])[energy > alpha][0] + 1\n",
    "        lam = lam[:i_end]\n",
    "        v = v[:, ::-1]\n",
    "        v = v[:, :i_end]\n",
    "        self.lam = lam\n",
    "        self.sqrt_lam = np.sqrt(lam)\n",
    "        self.v = v\n",
    "        self.energy = energy\n",
    "        self.num_xi = i_end\n",
    "        self.x_prev = None\n",
    "\n",
    "    def eval_phi(self, x):\n",
    "        \"\"\"\n",
    "        Evaluate the eigenfunctions at x.\n",
    "        \"\"\"\n",
    "        if self.X is not None:\n",
    "            KXx = self.k.K(self.X, x)\n",
    "            LiKXx = np.linalg.solve(self.L, KXx)\n",
    "            m = np.dot(LiKXx.T, self.LiY)\n",
    "            Kc = self.k.K(x, self.Xq) - np.dot(LiKXx.T, self.LiKcp)\n",
    "            self.tmp_mu = m\n",
    "        else:\n",
    "            Kc = self.k.K(x, self.Xq)\n",
    "            self.tmp_mu = 0.\n",
    "        phi = np.einsum('i,ji,j,rj->ri', 1. / self.lam, self.v, self.wq, Kc)\n",
    "        return phi\n",
    "    \n",
    "    def __call__(self, x, xi):\n",
    "        \"\"\"\n",
    "        Evaluate the expansion at x and xi.\n",
    "        \"\"\"\n",
    "        if self.x_prev is not x:\n",
    "            self.x_prev = x\n",
    "            self.tmp_phi = self.eval_phi(x)\n",
    "        print self.tmp_mu\n",
    "        return self.tmp_mu + np.dot(self.tmp_phi, xi * self.sqrt_lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# First, let's fit a Gaussian process to the data.\n",
    "# This will automatically determine the best lengthscale and variance by maximizing the likelihood\n",
    "k1 = GPy.kern.Exponential(3, ARD=True)\n",
    "k1.lengthscale.constrain_fixed([0.1, 0.1, 0.1])\n",
    "k_permX = k1\n",
    "# There are not enough data to find the X and Y length scales. We need to fix their values to the \n",
    "# persumed variability.\n",
    "# Center the data about 0\n",
    "m0 = Y_obs.mean(axis=0)\n",
    "model_permX = GPy.models.GPRegression(X_obs, Y_obs[:, 0:1] - m0[0], k_permX)\n",
    "# We do not want the field to have any noise\n",
    "model_permX.likelihood.variance.constrain_fixed(1e-12)\n",
    "# Let the GP optimize for just the variance of the kernel\n",
    "model_permX.optimize()\n",
    "print str(model_permX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now from this, you can actually take samples at any grid you want.\n",
    "# For relatively small grids. This is because the following actually sets up and does Cholesky on a\n",
    "# (nx x ny x nz) x (nx x ny x nz) matrix... \n",
    "#Kx = model_permX.posterior_samples(X_all, 10)\n",
    "# Each column is a sample\n",
    "#print Kx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, let's use the Nystrom to the KLE.\n",
    "# nq controls the accuracy of the approximation (number of quadrature points per dimension)\n",
    "# We must start low and keep increasing it, until the approximation does not change\n",
    "fig, ax = plt.subplots()\n",
    "for nq in [2, 4, 8, 16, 32]:\n",
    "    # Notice that here I give the kernel with the optimized parameters\n",
    "    kle_permX = KarhunenLoeveExpansion(model_permX.kern, nq=nq, alpha=0.95, X=X_obs, Y=Y_obs[:,0] - m0[0])\n",
    "    print 'nq = {0:d}, num_terms = {1:d}'.format(nq, kle_permX.num_xi)\n",
    "    ax.plot(kle_permX.lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kx = kle_permX(X_all, np.random.randn(kle_permX.num_xi)) + m0[0] # Remember to add back the constant mean\n",
    "print Kx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second time must bef much faster - Maybe save the object in the pickle file after the first evaluation.\n",
    "Kx = kle_permX(X_all, np.random.randn(kle_permX.num_xi))\n",
    "print Kx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(X1[:, :, 0], X2[:, :, 0], Kx.reshape(X1.shape)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second time must bef much faster:\n",
    "Kxs = []\n",
    "for i in xrange(5):\n",
    "    #Kx = kle_permX(X_all, np.random.randn(kle_permX.num_xi)) + m0[0]\n",
    "    Kx = model_permX.posterior_samples_f(X_all)[:,0] + m0[0]\n",
    "    print i\n",
    "    Kxs.append(Kx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(i=0):\n",
    "    for Kx in Kxs[:1]:\n",
    "        fig, ax = plt.subplots()\n",
    "        c = ax.contourf(X1[:, :, 0], X2[:, :, 0], Kx.reshape(X1.shape)[:, :, i])\n",
    "        plt.colorbar(c)\n",
    "        \n",
    "from ipywidgets import interactive\n",
    "interactive(plot_contour, i=(0, 14, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "# the parameter nq controls the accuracy of the Nystrom approximation.\n",
    "k_permX = GPy.kern.Exponential(3, ARD=True)\n",
    "# First, let's \n",
    "\n",
    "# You should start low and gradually increase it until it does not change a lot.\n",
    "kle_permX = KarhunenLoeveExpansion(k_permX, nq=60, alpha=0.95, X=X_obs, Y=Y_obs[:,0])\n",
    "ax.plot(kle_permX.lam)\n",
    "#handler_permX = open('permX', 'wb')\n",
    "#pickle.dump(kle_permX, handler_permX) \n",
    "with open('permX8.pcl', 'wb') as fp:\n",
    "    pickle.dump(kle_permX, fp)\n",
    "#handler_permX.close()\n",
    "#kle_permY = KarhunenLoeveExpansion(k, nq=512, alpha=0.95, X=X_obs, Y=Y_obs[:,1])\n",
    "#handler_permY = open('permY', 'wb')\n",
    "#pickle.dump(kle_permY, handler_permY) \n",
    "#kle_permZ = KarhunenLoeveExpansion(k, nq=512, alpha=0.95, X=X_obs, Y=Y_obs[:,2])\n",
    "#handler_permZ = open('permZ', 'wb')\n",
    "#pickle.dump(kle_permZ, handler_permZ)\n",
    "#k_poro = GPy.kern.Exponential(3, ARD=True)\n",
    "#k_poro = GPy.kern.RBF(3, ARD=True)\n",
    "#kle_poro  = KarhunenLoeveExpansion(k_poro, nq=512, alpha=0.95, X=X_obs, Y=Y_obs[:,3])\n",
    "#handler_poro  = open('poro' , 'wb')\n",
    "#pickle.dump(kle_poro, handler_poro)\n",
    "\n",
    "print 'Number of terms for permX:', kle_permX.num_xi\n",
    "#print 'Number of terms for permY:', kle_permY.num_xi\n",
    "#print 'Number of terms for permZ:', kle_permZ.num_xi\n",
    "#print 'Number of terms for poro :', kle_poro.num_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
